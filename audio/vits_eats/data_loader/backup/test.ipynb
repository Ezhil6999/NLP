{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea909dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams():\n",
    "  def __init__(self, **kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "      if type(v) == dict:\n",
    "        v = HParams(**v)\n",
    "      self[k] = v\n",
    "    \n",
    "  def keys(self):\n",
    "    return self.__dict__.keys()\n",
    "\n",
    "  def items(self):\n",
    "    return self.__dict__.items()\n",
    "\n",
    "  def values(self):\n",
    "    return self.__dict__.values()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.__dict__)\n",
    "\n",
    "  def __getitem__(self, key):\n",
    "    return getattr(self, key)\n",
    "\n",
    "  def __setitem__(self, key, value):\n",
    "    return setattr(self, key, value)\n",
    "\n",
    "  def __contains__(self, key):\n",
    "    return key in self.__dict__\n",
    "\n",
    "  def __repr__(self):\n",
    "    return self.__dict__.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c23915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'name': 'Transformer', 'hidden_size': 256, 'num_layers': 6, 'dropout': 0.1}, 'training': {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0005}, 'data': {'train_path': 'data/train.csv', 'val_path': 'data/val.csv'}}\n",
      "3\n",
      "dict_keys(['model', 'training', 'data'])\n",
      "dict_values([{'name': 'Transformer', 'hidden_size': 256, 'num_layers': 6, 'dropout': 0.1}, {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0005}, {'train_path': 'data/train.csv', 'val_path': 'data/val.csv'}])\n",
      "dict_items([('model', {'name': 'Transformer', 'hidden_size': 256, 'num_layers': 6, 'dropout': 0.1}), ('training', {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0005}), ('data', {'train_path': 'data/train.csv', 'val_path': 'data/val.csv'})])\n",
      "256\n",
      "0.0005\n",
      "data/train.csv\n"
     ]
    }
   ],
   "source": [
    "hparams = HParams(\n",
    "    model={\n",
    "        \"name\": \"Transformer\",\n",
    "        \"hidden_size\": 256,\n",
    "        \"num_layers\": 6,\n",
    "        \"dropout\": 0.1\n",
    "    },\n",
    "    training={\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 20,\n",
    "        \"learning_rate\": 0.0005\n",
    "    },\n",
    "    data={\n",
    "        \"train_path\": \"data/train.csv\",\n",
    "        \"val_path\": \"data/val.csv\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(hparams)\n",
    "print(len(hparams))\n",
    "print(hparams.keys())\n",
    "print(hparams.values())\n",
    "print(hparams.items())\n",
    "\n",
    "print(hparams.model.hidden_size)\n",
    "print(hparams.training.learning_rate)\n",
    "print(hparams[\"data\"].train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c850956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"C:\\Ezhil\\NLP\\audio\\vits_eats\\config\\config.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bc72b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'log_interval': 200, 'eval_interval': 1000, 'seed': 1234, 'epochs': 20000, 'learning_rate': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 64, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 8192, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'training_files': 'filelists/ljs_audio_text_train_filelist.txt.cleaned', 'validation_files': 'filelists/ljs_audio_text_val_filelist.txt.cleaned', 'text_cleaners': ['english_cleaners2'], 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': None, 'add_blank': True, 'n_speakers': 0, 'cleaned_text': True}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HParams(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b247c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Ezhil\\Downloads\\LJSpeech-1.1\\LJSpeech-1.1\\wavs\\LJ001-0003.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deb2a080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426342"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.getsize(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6854139d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(path) // (2 * 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78222f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor([0.0000000001, 0.01, 1.0, 100.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd24af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-05, 1.0000e-02, 1.0000e+00, 1.0000e+02])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(x, min=1e-5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca54094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (env310)",
   "language": "python",
   "name": "env310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
